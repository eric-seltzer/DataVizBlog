---
title: "Predicting if a NBA Team Will Make the Playoffs"
author: "Eric Seltzer"
date: "2024-03-06"
categories: [sports, code, analysis, data wrangling]
---
# Intoduction
For this blog post, I wanted to take on more of a challenging idea which was to both create a prediction model and visualize that data. To to this, I also wanted to combine this with my passion for sports, particularly basketball. It felt only right to use NBA data to accomplish this. On Data World, I found a data set that had team stats from the 97-98 season all the way until the 21-22 season.
```{r}
#| output: false
# loading in necessary packages
library(tidyverse)
library(here)
library(kableExtra)
library(broom)
library(modelr)
library(knitr)
```

```{r}
#| output: false
# loading in data set
team_stats <- read_csv(here('data/NBA_Team_Stats.csv'))
```
Here is an example of what the data set looks like directly from the source.

# Original Data Set
```{r}
kable(head(team_stats))
```

My first step in this project is to clean and format this data in a way so that I can work with it how I want too. Below is a table showing what all the variable names mean.

# Variable Explanations
| Variable | Description                                                                |
|----------|----------------------------------------------------------------------------|
| No       | End of Season Ranking (1 winning the Finals)                               |
| Team     | NBA Team Name                                                              |
| G        | Games Played                                                               |
| Min      | Average Minutes Per Game                                                   |
| Pts      | Average Points Per Game                                                    |
| Reb      | Average Rebounds Per Game                                                  |
| Ast      | Average Assists Per Game                                                   |
| Stl      | Average Steals Per Game                                                    |
| Blk      | Average Blocks Per Game                                                    |
| To       | Average Turnovers Per Game                                                 |
| Pf       | Average Fouls Per Game                                                     |
| Dreb     | Average Defensive Rebounds Per Game                                        |
| Oreb     | Average Offensive Rebounds Per Game                                        |
| Fgm-a    | Average Field Goals Made Per Game - Average Field Goals Attempted Per Game |
| 3gm-a    | Average 3 Pointers Made Per Game - Average 3 Pointers Attempted Per Game   |
| Ftm-a    | Average Free Throws Made Per Game - Average Free Throws Attempted Per Game |
| Eff      | NBA Efficiency Recap                                                       |
| Deff     | Efficiency Recap Difference                                                |
| Year     | Year of the NBA Season                                                     |
Side Note: 

NBA Efficiency Recap = ((Points + Rebounds + Assists + Steals + Blocks) - ((Field Goal Attempts - Field Goals Made) + (Free Throw Attempts - Free Throws Made) + Turnovers))

Efficiency Recap Difference = Efficiency Recap - Opponent's Efficiency Recap

# Data Cleaning
```{r}
team_stats_tidy <-
  team_stats |>
  mutate(Team = factor(Team))
team_stats_tidy <-
  team_stats_tidy |>
  mutate(Team = fct_recode(Team,
                           Bulls = "Chicago",
                           Jazz = "Utah",
                           Suns = "Phoenix",
                           Lakers = "L.A.Lakers",
                           Spurs = "San Antonio",
                           Pacers = "Indiana", 
                           Heat = "Miami",
                           Thunder = "Seattle", 
                           Hawks = "Atlanta", 
                           Knicks = "New York",
                           Cavaliers = "Cleveland",
                           Hornets = "Charlotte",
                           Trailblazers = "Portland", 
                           Timberwolves = "Minnesota",
                           Wizards = "Washington",
                           Pistons = "Detroit",
                           Nets = "New Jersey",
                           Bucks = "Milwaukee",
                           Magic = "Orlando",
                           Rockets = "Houston",
                           Celtics = "Boston",
                           `76ers` = "Philadelphia",
                           Kings = "Sacramento",
                           Mavericks = "Dallas",
                           Grizzlies = "Vancouver",
                           Clippers = "L.A.Clippers",
                           Warriors = "Golden State",
                           Raptors = "Toronto",
                           Nuggets = "Denver",
                           Pelicans = "New Orleans",
                           Grizzlies = "Memphis",
                           Nets = "Brooklyn",
                           Thunder = "Oklahoma City"))
```

```{r}
team_stats_tidy <-
  team_stats_tidy |>
  separate(`Fgm-a`,
           sep = "-",
           into = c("FGM", "FGA")) |>
  separate(`3gm-a`,
           sep = "-",
           into = c("3PM", "3PA")) |>
  separate(`Ftm-a`,
           sep = "-",
           into = c("FTM", "FTA"))
```

```{r}
team_stats_tidy <-
  team_stats_tidy |>
  rename(FG_pct = Pct...15,
         `3P_pct` = Pct...17,
         FT_pct = Pct...19) |>
  mutate(FGM = as.numeric(FGM),
         FGA = as.numeric(FGA),
         `3PM` = as.numeric(`3PM`),
         `3PA` = as.numeric(`3PA`),
         FTM = as.numeric(FTM),
         FTA = as.numeric(FTA),
         FG_pct = FG_pct * 100,
         `3P_pct` = `3P_pct` * 100,
         FT_pct = FT_pct * 100) |>
  mutate(Year = str_sub(Year,
                        6),
         Year = as.numeric(Year))
```

```{r}
team_stats_tidy <-
  team_stats_tidy |>
  mutate(Conference = if_else(Team %in% c("Celtics", "Bucks", "Cavaliers", "Knicks", "76ers", "Magic", "Heat", "Pacers", "Bulls", "Hawks", "Nets", "Raptors", "Hornets", "Wizards", "Pistons"), "East", "West"),
         Playoffs = if_else(G > 82, 1, 0))
```

# Cleaned Data Set
Here is an example of what the data now looks like
```{r}
kable(head(team_stats_tidy))
```

# Building A Model
I decided to use some of the metrics in the data set to predict whether a team would make the playoffs or not. I made a response variables Playoffs by using a condition of if a team played more than 82 games or not in season.

In order to make sure that this model isn't testing using data that knows the answer, we should get rid of both of the No and G variables. We also don't care about what team it is so we should get rid of the team factor.
```{r}
team_stats_tidy <-
  team_stats_tidy |>
  select(-(c("No","G", "Team")))
```

I am only going to choose two predictors that were found to be relatively significant in a model using all the predictors. One is Conference which will allow me to compare between the East and the West and the other is Deff. As mentioned above, Deff factors in most other metrics vs their opponents. Shown below is my model with their coefficients and p values.

```{r}
playoffs_mod <- 
  glm(Playoffs ~ Deff + Conference,
                    data = team_stats_tidy,
                    family = 'binomial')
kable(tidy(playoffs_mod))
```

```{r}
grid <-
  team_stats_tidy |>
  data_grid(
    Deff = seq_range(Deff, n = 60),
    Conference = c("West", "East")
  )
```

```{r}
aug <-
  augment(playoffs_mod,
          newdata = grid,
          se_fit = TRUE)
```

Next I need to convert the .fitted values to predicted probabilities. Currently they are showing the predicted log odds.
```{r}
aug <-
  aug |>
  mutate(.predprob = (exp(.fitted) / (1 + exp(.fitted))))
```

For my visualization I plan on using the geom_rug feature, so I need to make two separate data frames with teams that made the playoffs and teams that didn't.
```{r}
stats_playoffs <-
  team_stats_tidy |>
  filter(Playoffs == 1)

stats_nplayoffs <-
  team_stats_tidy |>
  filter(Playoffs == 0)
```

# Figure 1
```{r}
#|fig-width: 12
aug |>
  ggplot(aes(x = Deff,
             y = .predprob)) +
  geom_line(aes(colour = Conference),
            linewidth = 1.2,
            alpha = 0.7) +
  scale_colour_viridis_d() +
  geom_rug(data = stats_playoffs,
           sides = 't',
           alpha = 0.3,
           aes(y = Playoffs)) +
  geom_rug(data = stats_nplayoffs,
           sides = 'b',
           alpha = 0.3,
           aes(y = Playoffs)) +
  labs(x = "Efficiency Recap Rating",
       y = "Predicted Probability",
       colour = "Conference",
       title = "Probability of an NBA Team to Make the Playoffs",
       caption = "(based on data from NBA via data world from 1998 - 2022)") +
  theme_minimal() +
    theme(axis.title = element_text(size = 10,),
        strip.text = element_text(size = 12),
        plot.title = element_text(size = 16,
                                  hjust = 0),
        plot.subtitle = element_text(size = 6),
        panel.spacing = unit(1, 'lines'),
        strip.text.x = element_text(color = "black", 
                                    face = "bold"),
        strip.background = element_rect(colour = "black",
                                        fill = "ivory"),
        panel.background = element_rect(fill = "ivory"),
        plot.background = element_rect(fill = "ivory"),
        plot.caption = element_text(hjust = 1.5)) +
  scale_x_continuous(breaks=seq(-30, 40, 10))
```

# Conclusion
This plot shows the differences in the probability of a team to make the playoffs dependent on their efficiency recap rating and their conference. Shown in this plot is that for a team in the Eastern Conference, they need a lower efficiency recap rating to have over a 0.5 probability of making the playoffs. One could imply from the 1997-98 season until the 2021-22 season, it is has been easier to make the playoffs in the Eastern Conference.

# Connections to Class
In this blog, I used many tactics from class. One being the data visualization aspects of faceting, and grouping. I put the geom_rug on as well and am visualizing my predicted probabilities for each observation. I also used our technique of creating a logistic regression model. 